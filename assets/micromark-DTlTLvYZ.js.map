{"version":3,"file":"micromark-DTlTLvYZ.js","sources":["../../node_modules/micromark/lib/initialize/content.js","../../node_modules/micromark/lib/initialize/document.js","../../node_modules/micromark/lib/initialize/flow.js","../../node_modules/micromark/lib/initialize/text.js","../../node_modules/micromark/lib/constructs.js","../../node_modules/micromark/lib/create-tokenizer.js","../../node_modules/micromark/lib/parse.js","../../node_modules/micromark/lib/postprocess.js","../../node_modules/micromark/lib/preprocess.js"],"sourcesContent":["/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n};\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Initializer}\n *   Content.\n */\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(this.parser.constructs.contentInitial, afterContentStartConstruct, paragraphInitial);\n  /** @type {Token} */\n  let previous;\n  return contentStart;\n\n  /** @type {State} */\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return factorySpace(effects, contentStart, \"linePrefix\");\n  }\n\n  /** @type {State} */\n  function paragraphInitial(code) {\n    effects.enter(\"paragraph\");\n    return lineStart(code);\n  }\n\n  /** @type {State} */\n  function lineStart(code) {\n    const token = effects.enter(\"chunkText\", {\n      contentType: \"text\",\n      previous\n    });\n    if (previous) {\n      previous.next = token;\n    }\n    previous = token;\n    return data(code);\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === null) {\n      effects.exit(\"chunkText\");\n      effects.exit(\"paragraph\");\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      effects.exit(\"chunkText\");\n      return lineStart;\n    }\n\n    // Data.\n    effects.consume(code);\n    return data;\n  }\n}","/**\n * @import {\n *   Construct,\n *   ContainerState,\n *   InitialConstruct,\n *   Initializer,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @typedef {[Construct, ContainerState]} StackItem\n *   Construct and its state.\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { splice } from 'micromark-util-chunked';\n/** @type {InitialConstruct} */\nexport const document = {\n  tokenize: initializeDocument\n};\n\n/** @type {Construct} */\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeDocument(effects) {\n  const self = this;\n  /** @type {Array<StackItem>} */\n  const stack = [];\n  let continued = 0;\n  /** @type {TokenizeContext | undefined} */\n  let childFlow;\n  /** @type {Token | undefined} */\n  let childToken;\n  /** @type {number} */\n  let lineStartOffset;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued];\n      self.containerState = item[1];\n      return effects.attempt(item[0].continuation, documentContinue, checkNewContainers)(code);\n    }\n\n    // Done.\n    return checkNewContainers(code);\n  }\n\n  /** @type {State} */\n  function documentContinue(code) {\n    continued++;\n\n    // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined;\n      if (childFlow) {\n        closeFlow();\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the flow chunk.\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          point = self.events[indexBeforeFlow][1].end;\n          break;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      let index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n      return checkNewContainers(code);\n    }\n    return start(code);\n  }\n\n  /** @type {State} */\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code);\n      }\n\n      // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code);\n      }\n\n      // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n      // To do: next major: remove `_gfmTableDynamicInterruptHack` (no longer\n      // needed in micromark-extension-gfm-table@1.0.6).\n      self.interrupt = Boolean(childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack);\n    }\n\n    // Check if there is a new container.\n    self.containerState = {};\n    return effects.check(containerConstruct, thereIsANewContainer, thereIsNoNewContainer)(code);\n  }\n\n  /** @type {State} */\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow();\n    exitContainers(continued);\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length;\n    lineStartOffset = self.now().offset;\n    return flowStart(code);\n  }\n\n  /** @type {State} */\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {};\n    return effects.attempt(containerConstruct, containerContinue, flowStart)(code);\n  }\n\n  /** @type {State} */\n  function containerContinue(code) {\n    continued++;\n    stack.push([self.currentConstruct, self.containerState]);\n    // Try another.\n    return documentContinued(code);\n  }\n\n  /** @type {State} */\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow();\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    childFlow = childFlow || self.parser.flow(self.now());\n    effects.enter(\"chunkFlow\", {\n      _tokenizer: childFlow,\n      contentType: \"flow\",\n      previous: childToken\n    });\n    return flowContinue(code);\n  }\n\n  /** @type {State} */\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit(\"chunkFlow\"), true);\n      exitContainers(0);\n      effects.consume(code);\n      return;\n    }\n    if (markdownLineEnding(code)) {\n      effects.consume(code);\n      writeToChild(effects.exit(\"chunkFlow\"));\n      // Get ready for the next line.\n      continued = 0;\n      self.interrupt = undefined;\n      return start;\n    }\n    effects.consume(code);\n    return flowContinue;\n  }\n\n  /**\n   * @param {Token} token\n   *   Token.\n   * @param {boolean | undefined} [endOfFile]\n   *   Whether the token is at the end of the file (default: `false`).\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function writeToChild(token, endOfFile) {\n    const stream = self.sliceStream(token);\n    if (endOfFile) stream.push(null);\n    token.previous = childToken;\n    if (childToken) childToken.next = token;\n    childToken = token;\n    childFlow.defineSkip(token.start);\n    childFlow.write(stream);\n\n    // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length;\n      while (index--) {\n        if (\n        // The token starts before the line ending…\n        childFlow.events[index][1].start.offset < lineStartOffset && (\n        // …and either is not ended yet…\n        !childFlow.events[index][1].end ||\n        // …or ends after it.\n        childFlow.events[index][1].end.offset > lineStartOffset)) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return;\n        }\n      }\n\n      // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n      const indexBeforeExits = self.events.length;\n      let indexBeforeFlow = indexBeforeExits;\n      /** @type {boolean | undefined} */\n      let seen;\n      /** @type {Point | undefined} */\n      let point;\n\n      // Find the previous chunk (the one before the lazy line).\n      while (indexBeforeFlow--) {\n        if (self.events[indexBeforeFlow][0] === 'exit' && self.events[indexBeforeFlow][1].type === \"chunkFlow\") {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end;\n            break;\n          }\n          seen = true;\n        }\n      }\n      exitContainers(continued);\n\n      // Fix positions.\n      index = indexBeforeExits;\n      while (index < self.events.length) {\n        self.events[index][1].end = {\n          ...point\n        };\n        index++;\n      }\n\n      // Inject the exits earlier (they’re still also at the end).\n      splice(self.events, indexBeforeFlow + 1, 0, self.events.slice(indexBeforeExits));\n\n      // Discard the duplicate exits.\n      self.events.length = index;\n    }\n  }\n\n  /**\n   * @param {number} size\n   *   Size.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function exitContainers(size) {\n    let index = stack.length;\n\n    // Exit open containers.\n    while (index-- > size) {\n      const entry = stack[index];\n      self.containerState = entry[1];\n      entry[0].exit.call(self, effects);\n    }\n    stack.length = size;\n  }\n  function closeFlow() {\n    childFlow.write([null]);\n    childToken = undefined;\n    childFlow = undefined;\n    self.containerState._closeFlow = undefined;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n *   Tokenizer.\n */\nfunction tokenizeContainer(effects, ok, nok) {\n  // Always populated by defaults.\n\n  return factorySpace(effects, effects.attempt(this.parser.constructs.document, ok, nok), \"linePrefix\", this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4);\n}","/**\n * @import {\n *   InitialConstruct,\n *   Initializer,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nimport { blankLine, content } from 'micromark-core-commonmark';\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n};\n\n/**\n * @this {TokenizeContext}\n *   Self.\n * @type {Initializer}\n *   Initializer.\n */\nfunction initializeFlow(effects) {\n  const self = this;\n  const initial = effects.attempt(\n  // Try to parse a blank line.\n  blankLine, atBlankEnding,\n  // Try to parse initial flow (essentially, only code).\n  effects.attempt(this.parser.constructs.flowInitial, afterConstruct, factorySpace(effects, effects.attempt(this.parser.constructs.flow, afterConstruct, effects.attempt(content, afterConstruct)), \"linePrefix\")));\n  return initial;\n\n  /** @type {State} */\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEndingBlank\");\n    effects.consume(code);\n    effects.exit(\"lineEndingBlank\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n\n  /** @type {State} */\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code);\n      return;\n    }\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    self.currentConstruct = undefined;\n    return initial;\n  }\n}","/**\n * @import {\n *   Code,\n *   InitialConstruct,\n *   Initializer,\n *   Resolver,\n *   State,\n *   TokenizeContext\n * } from 'micromark-util-types'\n */\n\nexport const resolver = {\n  resolveAll: createResolver()\n};\nexport const string = initializeFactory('string');\nexport const text = initializeFactory('text');\n\n/**\n * @param {'string' | 'text'} field\n *   Field.\n * @returns {InitialConstruct}\n *   Construct.\n */\nfunction initializeFactory(field) {\n  return {\n    resolveAll: createResolver(field === 'text' ? resolveAllLineSuffixes : undefined),\n    tokenize: initializeText\n  };\n\n  /**\n   * @this {TokenizeContext}\n   *   Context.\n   * @type {Initializer}\n   */\n  function initializeText(effects) {\n    const self = this;\n    const constructs = this.parser.constructs[field];\n    const text = effects.attempt(constructs, start, notText);\n    return start;\n\n    /** @type {State} */\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code);\n    }\n\n    /** @type {State} */\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code);\n        return;\n      }\n      effects.enter(\"data\");\n      effects.consume(code);\n      return data;\n    }\n\n    /** @type {State} */\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit(\"data\");\n        return text(code);\n      }\n\n      // Data.\n      effects.consume(code);\n      return data;\n    }\n\n    /**\n     * @param {Code} code\n     *   Code.\n     * @returns {boolean}\n     *   Whether the code is a break.\n     */\n    function atBreak(code) {\n      if (code === null) {\n        return true;\n      }\n      const list = constructs[code];\n      let index = -1;\n      if (list) {\n        // Always populated by defaults.\n\n        while (++index < list.length) {\n          const item = list[index];\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true;\n          }\n        }\n      }\n      return false;\n    }\n  }\n}\n\n/**\n * @param {Resolver | undefined} [extraResolver]\n *   Resolver.\n * @returns {Resolver}\n *   Resolver.\n */\nfunction createResolver(extraResolver) {\n  return resolveAllText;\n\n  /** @type {Resolver} */\n  function resolveAllText(events, context) {\n    let index = -1;\n    /** @type {number | undefined} */\n    let enter;\n\n    // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === \"data\") {\n          enter = index;\n          index++;\n        }\n      } else if (!events[index] || events[index][1].type !== \"data\") {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end;\n          events.splice(enter + 2, index - enter - 2);\n          index = enter + 2;\n        }\n        enter = undefined;\n      }\n    }\n    return extraResolver ? extraResolver(events, context) : events;\n  }\n}\n\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = 0; // Skip first.\n\n  while (++eventIndex <= events.length) {\n    if ((eventIndex === events.length || events[eventIndex][1].type === \"lineEnding\") && events[eventIndex - 1][1].type === \"data\") {\n      const data = events[eventIndex - 1][1];\n      const chunks = context.sliceStream(data);\n      let index = chunks.length;\n      let bufferIndex = -1;\n      let size = 0;\n      /** @type {boolean | undefined} */\n      let tabs;\n      while (index--) {\n        const chunk = chunks[index];\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length;\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++;\n            bufferIndex--;\n          }\n          if (bufferIndex) break;\n          bufferIndex = -1;\n        }\n        // Number\n        else if (chunk === -2) {\n          tabs = true;\n          size++;\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++;\n          break;\n        }\n      }\n      if (size) {\n        const token = {\n          type: eventIndex === events.length || tabs || size < 2 ? \"lineSuffix\" : \"hardBreakTrailing\",\n          start: {\n            _bufferIndex: index ? bufferIndex : data.start._bufferIndex + bufferIndex,\n            _index: data.start._index + index,\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size\n          },\n          end: {\n            ...data.end\n          }\n        };\n        data.end = {\n          ...token.start\n        };\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token);\n        } else {\n          events.splice(eventIndex, 0, ['enter', token, context], ['exit', token, context]);\n          eventIndex += 2;\n        }\n      }\n      eventIndex++;\n    }\n  }\n  return events;\n}","/**\n * @import {Extension} from 'micromark-util-types'\n */\n\nimport { attention, autolink, blockQuote, characterEscape, characterReference, codeFenced, codeIndented, codeText, definition, hardBreakEscape, headingAtx, htmlFlow, htmlText, labelEnd, labelStartImage, labelStartLink, lineEnding, list, setextUnderline, thematicBreak } from 'micromark-core-commonmark';\nimport { resolver as resolveText } from './initialize/text.js';\n\n/** @satisfies {Extension['document']} */\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n};\n\n/** @satisfies {Extension['contentInitial']} */\nexport const contentInitial = {\n  [91]: definition\n};\n\n/** @satisfies {Extension['flowInitial']} */\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n};\n\n/** @satisfies {Extension['flow']} */\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n};\n\n/** @satisfies {Extension['string']} */\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n};\n\n/** @satisfies {Extension['text']} */\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n};\n\n/** @satisfies {Extension['insideSpan']} */\nexport const insideSpan = {\n  null: [attention, resolveText]\n};\n\n/** @satisfies {Extension['attentionMarkers']} */\nexport const attentionMarkers = {\n  null: [42, 95]\n};\n\n/** @satisfies {Extension['disable']} */\nexport const disable = {\n  null: []\n};","/**\n * @import {\n *   Chunk,\n *   Code,\n *   ConstructRecord,\n *   Construct,\n *   Effects,\n *   InitialConstruct,\n *   ParseContext,\n *   Point,\n *   State,\n *   TokenizeContext,\n *   Token\n * } from 'micromark-util-types'\n */\n\n/**\n * @callback Restore\n *   Restore the state.\n * @returns {undefined}\n *   Nothing.\n *\n * @typedef Info\n *   Info.\n * @property {Restore} restore\n *   Restore.\n * @property {number} from\n *   From.\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n *   Construct.\n * @param {Info} info\n *   Info.\n * @returns {undefined}\n *   Nothing.\n */\n\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { push, splice } from 'micromark-util-chunked';\nimport { resolveAll } from 'micromark-util-resolve-all';\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n *   Parser.\n * @param {InitialConstruct} initialize\n *   Construct.\n * @param {Omit<Point, '_bufferIndex' | '_index'> | undefined} [from]\n *   Point (optional).\n * @returns {TokenizeContext}\n *   Context.\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = {\n    _bufferIndex: -1,\n    _index: 0,\n    line: from && from.line || 1,\n    column: from && from.column || 1,\n    offset: from && from.offset || 0\n  };\n  /** @type {Record<string, number>} */\n  const columnStart = {};\n  /** @type {Array<Construct>} */\n  const resolveAllConstructs = [];\n  /** @type {Array<Chunk>} */\n  let chunks = [];\n  /** @type {Array<Token>} */\n  let stack = [];\n  /** @type {boolean | undefined} */\n  let consumed = true;\n\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n  const effects = {\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    consume,\n    enter,\n    exit,\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  };\n\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n  const context = {\n    code: null,\n    containerState: {},\n    defineSkip,\n    events: [],\n    now,\n    parser,\n    previous: null,\n    sliceSerialize,\n    sliceStream,\n    write\n  };\n\n  /**\n   * The state function.\n   *\n   * @type {State | undefined}\n   */\n  let state = initialize.tokenize.call(context, effects);\n\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n  let expectedCode;\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize);\n  }\n  return context;\n\n  /** @type {TokenizeContext['write']} */\n  function write(slice) {\n    chunks = push(chunks, slice);\n    main();\n\n    // Exit if we’re not done, resolve might change stuff.\n    if (chunks[chunks.length - 1] !== null) {\n      return [];\n    }\n    addResult(initialize, 0);\n\n    // Otherwise, resolve, and exit.\n    context.events = resolveAll(resolveAllConstructs, context.events, context);\n    return context.events;\n  }\n\n  //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs);\n  }\n\n  /** @type {TokenizeContext['sliceStream']} */\n  function sliceStream(token) {\n    return sliceChunks(chunks, token);\n  }\n\n  /** @type {TokenizeContext['now']} */\n  function now() {\n    // This is a hot path, so we clone manually instead of `Object.assign({}, point)`\n    const {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    } = point;\n    return {\n      _bufferIndex,\n      _index,\n      line,\n      column,\n      offset\n    };\n  }\n\n  /** @type {TokenizeContext['defineSkip']} */\n  function defineSkip(value) {\n    columnStart[value.line] = value.column;\n    accountForPotentialSkip();\n  }\n\n  //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function main() {\n    /** @type {number} */\n    let chunkIndex;\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index];\n\n      // If we’re in a buffer chunk, loop through it.\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index;\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0;\n        }\n        while (point._index === chunkIndex && point._bufferIndex < chunk.length) {\n          go(chunk.charCodeAt(point._bufferIndex));\n        }\n      } else {\n        go(chunk);\n      }\n    }\n  }\n\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   *   Code.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function go(code) {\n    consumed = undefined;\n    expectedCode = code;\n    state = state(code);\n  }\n\n  /** @type {Effects['consume']} */\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++;\n      point.column = 1;\n      point.offset += code === -3 ? 2 : 1;\n      accountForPotentialSkip();\n    } else if (code !== -1) {\n      point.column++;\n      point.offset++;\n    }\n\n    // Not in a string chunk.\n    if (point._bufferIndex < 0) {\n      point._index++;\n    } else {\n      point._bufferIndex++;\n\n      // At end of string chunk.\n      if (point._bufferIndex ===\n      // Points w/ non-negative `_bufferIndex` reference\n      // strings.\n      /** @type {string} */\n      chunks[point._index].length) {\n        point._bufferIndex = -1;\n        point._index++;\n      }\n    }\n\n    // Expose the previous character.\n    context.previous = code;\n\n    // Mark as consumed.\n    consumed = true;\n  }\n\n  /** @type {Effects['enter']} */\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {};\n    token.type = type;\n    token.start = now();\n    context.events.push(['enter', token, context]);\n    stack.push(token);\n    return token;\n  }\n\n  /** @type {Effects['exit']} */\n  function exit(type) {\n    const token = stack.pop();\n    token.end = now();\n    context.events.push(['exit', token, context]);\n    return token;\n  }\n\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from);\n  }\n\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n  function onsuccessfulcheck(_, info) {\n    info.restore();\n  }\n\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   *   Callback.\n   * @param {{interrupt?: boolean | undefined} | undefined} [fields]\n   *   Fields.\n   */\n  function constructFactory(onreturn, fields) {\n    return hook;\n\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Array<Construct> | ConstructRecord | Construct} constructs\n     *   Constructs.\n     * @param {State} returnState\n     *   State.\n     * @param {State | undefined} [bogusState]\n     *   State.\n     * @returns {State}\n     *   State.\n     */\n    function hook(constructs, returnState, bogusState) {\n      /** @type {ReadonlyArray<Construct>} */\n      let listOfConstructs;\n      /** @type {number} */\n      let constructIndex;\n      /** @type {Construct} */\n      let currentConstruct;\n      /** @type {Info} */\n      let info;\n      return Array.isArray(constructs) ? /* c8 ignore next 1 */\n      handleListOfConstructs(constructs) : 'tokenize' in constructs ?\n      // Looks like a construct.\n      handleListOfConstructs([(/** @type {Construct} */constructs)]) : handleMapOfConstructs(constructs);\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleMapOfConstructs(map) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          const left = code !== null && map[code];\n          const all = code !== null && map.null;\n          const list = [\n          // To do: add more extension tests.\n          /* c8 ignore next 2 */\n          ...(Array.isArray(left) ? left : left ? [left] : []), ...(Array.isArray(all) ? all : all ? [all] : [])];\n          return handleListOfConstructs(list)(code);\n        }\n      }\n\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ReadonlyArray<Construct>} list\n       *   Constructs.\n       * @returns {State}\n       *   State.\n       */\n      function handleListOfConstructs(list) {\n        listOfConstructs = list;\n        constructIndex = 0;\n        if (list.length === 0) {\n          return bogusState;\n        }\n        return handleConstruct(list[constructIndex]);\n      }\n\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       *   Construct.\n       * @returns {State}\n       *   State.\n       */\n      function handleConstruct(construct) {\n        return start;\n\n        /** @type {State} */\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store();\n          currentConstruct = construct;\n          if (!construct.partial) {\n            context.currentConstruct = construct;\n          }\n\n          // Always populated by defaults.\n\n          if (construct.name && context.parser.constructs.disable.null.includes(construct.name)) {\n            return nok(code);\n          }\n          return construct.tokenize.call(\n          // If we do have fields, create an object w/ `context` as its\n          // prototype.\n          // This allows a “live binding”, which is needed for `interrupt`.\n          fields ? Object.assign(Object.create(context), fields) : context, effects, ok, nok)(code);\n        }\n      }\n\n      /** @type {State} */\n      function ok(code) {\n        consumed = true;\n        onreturn(currentConstruct, info);\n        return returnState;\n      }\n\n      /** @type {State} */\n      function nok(code) {\n        consumed = true;\n        info.restore();\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex]);\n        }\n        return bogusState;\n      }\n    }\n  }\n\n  /**\n   * @param {Construct} construct\n   *   Construct.\n   * @param {number} from\n   *   From.\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct);\n    }\n    if (construct.resolve) {\n      splice(context.events, from, context.events.length - from, construct.resolve(context.events.slice(from), context));\n    }\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context);\n    }\n  }\n\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   *   Info.\n   */\n  function store() {\n    const startPoint = now();\n    const startPrevious = context.previous;\n    const startCurrentConstruct = context.currentConstruct;\n    const startEventsIndex = context.events.length;\n    const startStack = Array.from(stack);\n    return {\n      from: startEventsIndex,\n      restore\n    };\n\n    /**\n     * Restore state.\n     *\n     * @returns {undefined}\n     *   Nothing.\n     */\n    function restore() {\n      point = startPoint;\n      context.previous = startPrevious;\n      context.currentConstruct = startCurrentConstruct;\n      context.events.length = startEventsIndex;\n      stack = startStack;\n      accountForPotentialSkip();\n    }\n  }\n\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {undefined}\n   *   Nothing.\n   */\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line];\n      point.offset += columnStart[point.line] - 1;\n    }\n  }\n}\n\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {Pick<Token, 'end' | 'start'>} token\n *   Token.\n * @returns {Array<Chunk>}\n *   Chunks.\n */\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index;\n  const startBufferIndex = token.start._bufferIndex;\n  const endIndex = token.end._index;\n  const endBufferIndex = token.end._bufferIndex;\n  /** @type {Array<Chunk>} */\n  let view;\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];\n  } else {\n    view = chunks.slice(startIndex, endIndex);\n    if (startBufferIndex > -1) {\n      const head = view[0];\n      if (typeof head === 'string') {\n        view[0] = head.slice(startBufferIndex);\n      } else {\n        view.shift();\n      }\n    }\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex));\n    }\n  }\n  return view;\n}\n\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {ReadonlyArray<Chunk>} chunks\n *   Chunks.\n * @param {boolean | undefined} [expandTabs=false]\n *   Whether to expand tabs (default: `false`).\n * @returns {string}\n *   Result.\n */\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1;\n  /** @type {Array<string>} */\n  const result = [];\n  /** @type {boolean | undefined} */\n  let atTab;\n  while (++index < chunks.length) {\n    const chunk = chunks[index];\n    /** @type {string} */\n    let value;\n    if (typeof chunk === 'string') {\n      value = chunk;\n    } else switch (chunk) {\n      case -5:\n        {\n          value = \"\\r\";\n          break;\n        }\n      case -4:\n        {\n          value = \"\\n\";\n          break;\n        }\n      case -3:\n        {\n          value = \"\\r\" + \"\\n\";\n          break;\n        }\n      case -2:\n        {\n          value = expandTabs ? \" \" : \"\\t\";\n          break;\n        }\n      case -1:\n        {\n          if (!expandTabs && atTab) continue;\n          value = \" \";\n          break;\n        }\n      default:\n        {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk);\n        }\n    }\n    atTab = chunk === -2;\n    result.push(value);\n  }\n  return result.join('');\n}","/**\n * @import {\n *   Create,\n *   FullNormalizedExtension,\n *   InitialConstruct,\n *   ParseContext,\n *   ParseOptions\n * } from 'micromark-util-types'\n */\n\nimport { combineExtensions } from 'micromark-util-combine-extensions';\nimport { content } from './initialize/content.js';\nimport { document } from './initialize/document.js';\nimport { flow } from './initialize/flow.js';\nimport { string, text } from './initialize/text.js';\nimport * as defaultConstructs from './constructs.js';\nimport { createTokenizer } from './create-tokenizer.js';\n\n/**\n * @param {ParseOptions | null | undefined} [options]\n *   Configuration (optional).\n * @returns {ParseContext}\n *   Parser.\n */\nexport function parse(options) {\n  const settings = options || {};\n  const constructs = /** @type {FullNormalizedExtension} */\n  combineExtensions([defaultConstructs, ...(settings.extensions || [])]);\n\n  /** @type {ParseContext} */\n  const parser = {\n    constructs,\n    content: create(content),\n    defined: [],\n    document: create(document),\n    flow: create(flow),\n    lazy: {},\n    string: create(string),\n    text: create(text)\n  };\n  return parser;\n\n  /**\n   * @param {InitialConstruct} initial\n   *   Construct to start with.\n   * @returns {Create}\n   *   Create a tokenizer.\n   */\n  function create(initial) {\n    return creator;\n    /** @type {Create} */\n    function creator(from) {\n      return createTokenizer(parser, initial, from);\n    }\n  }\n}","/**\n * @import {Event} from 'micromark-util-types'\n */\n\nimport { subtokenize } from 'micromark-util-subtokenize';\n\n/**\n * @param {Array<Event>} events\n *   Events.\n * @returns {Array<Event>}\n *   Events.\n */\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n  return events;\n}","/**\n * @import {Chunk, Code, Encoding, Value} from 'micromark-util-types'\n */\n\n/**\n * @callback Preprocessor\n *   Preprocess a value.\n * @param {Value} value\n *   Value.\n * @param {Encoding | null | undefined} [encoding]\n *   Encoding when `value` is a typed array (optional).\n * @param {boolean | null | undefined} [end=false]\n *   Whether this is the last chunk (default: `false`).\n * @returns {Array<Chunk>}\n *   Chunks.\n */\n\nconst search = /[\\0\\t\\n\\r]/g;\n\n/**\n * @returns {Preprocessor}\n *   Preprocess a value.\n */\nexport function preprocess() {\n  let column = 1;\n  let buffer = '';\n  /** @type {boolean | undefined} */\n  let start = true;\n  /** @type {boolean | undefined} */\n  let atCarriageReturn;\n  return preprocessor;\n\n  /** @type {Preprocessor} */\n  // eslint-disable-next-line complexity\n  function preprocessor(value, encoding, end) {\n    /** @type {Array<Chunk>} */\n    const chunks = [];\n    /** @type {RegExpMatchArray | null} */\n    let match;\n    /** @type {number} */\n    let next;\n    /** @type {number} */\n    let startPosition;\n    /** @type {number} */\n    let endPosition;\n    /** @type {Code} */\n    let code;\n    value = buffer + (typeof value === 'string' ? value.toString() : new TextDecoder(encoding || undefined).decode(value));\n    startPosition = 0;\n    buffer = '';\n    if (start) {\n      // To do: `markdown-rs` actually parses BOMs (byte order mark).\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++;\n      }\n      start = undefined;\n    }\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition;\n      match = search.exec(value);\n      endPosition = match && match.index !== undefined ? match.index : value.length;\n      code = value.charCodeAt(endPosition);\n      if (!match) {\n        buffer = value.slice(startPosition);\n        break;\n      }\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3);\n        atCarriageReturn = undefined;\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5);\n          atCarriageReturn = undefined;\n        }\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition));\n          column += endPosition - startPosition;\n        }\n        switch (code) {\n          case 0:\n            {\n              chunks.push(65533);\n              column++;\n              break;\n            }\n          case 9:\n            {\n              next = Math.ceil(column / 4) * 4;\n              chunks.push(-2);\n              while (column++ < next) chunks.push(-1);\n              break;\n            }\n          case 10:\n            {\n              chunks.push(-4);\n              column = 1;\n              break;\n            }\n          default:\n            {\n              atCarriageReturn = true;\n              column = 1;\n            }\n        }\n      }\n      startPosition = endPosition + 1;\n    }\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5);\n      if (buffer) chunks.push(buffer);\n      chunks.push(null);\n    }\n    return chunks;\n  }\n}"],"names":["combineExtensions","factorySpace","markdownLineEnding","splice","push","blankLine","content$1","list","blockQuote","definition","codeIndented","headingAtx","thematicBreak","setextUnderline","htmlFlow","codeFenced","characterReference","characterEscape","lineEnding","labelStartImage","attention","autolink","htmlText","labelStartLink","hardBreakEscape","labelEnd","codeText","resolveAll","subtokenize","content","initializeContent","effects","contentStart","afterContentStartConstruct","paragraphInitial","previous","code","lineStart","token","data","document","initializeDocument","containerConstruct","tokenizeContainer","self","stack","continued","childFlow","childToken","lineStartOffset","start","item","documentContinue","checkNewContainers","closeFlow","indexBeforeExits","indexBeforeFlow","point","exitContainers","index","documentContinued","flowStart","thereIsANewContainer","thereIsNoNewContainer","containerContinue","flowContinue","writeToChild","endOfFile","stream","seen","size","entry","ok","nok","flow","initializeFlow","initial","atBlankEnding","afterConstruct","resolver","createResolver","string","initializeFactory","text","field","resolveAllLineSuffixes","initializeText","constructs","notText","atBreak","extraResolver","resolveAllText","events","context","enter","eventIndex","chunks","bufferIndex","tabs","chunk","contentInitial","flowInitial","insideSpan","resolveText","attentionMarkers","disable","defaultConstructs","createTokenizer","parser","initialize","from","columnStart","resolveAllConstructs","constructFactory","onsuccessfulconstruct","onsuccessfulcheck","consume","exit","defineSkip","now","sliceSerialize","sliceStream","write","state","slice","main","addResult","expandTabs","serializeChunks","sliceChunks","_bufferIndex","_index","line","column","offset","value","accountForPotentialSkip","chunkIndex","go","type","fields","construct","info","_","onreturn","hook","returnState","bogusState","listOfConstructs","constructIndex","currentConstruct","handleListOfConstructs","handleMapOfConstructs","map","left","all","handleConstruct","store","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","restore","startIndex","startBufferIndex","endIndex","endBufferIndex","view","head","result","atTab","parse","options","create","creator","postprocess","search","preprocess","buffer","atCarriageReturn","preprocessor","encoding","end","match","next","startPosition","endPosition"],"mappings":"AAAA,OAAA,KAAAA,OAAA,kDAAA,OAAA,KAAAC,MAAA,wCAAA,OAAA,KAAAC,MAAA,yCAAA,OAAA,KAAAC,EAAA,KAAAC,OAAA,uCAAA,OAAA,KAAAC,GAAA,KAAAC,GAAA,KAAAC,EAAA,KAAAC,GAAA,KAAAC,GAAA,KAAAC,EAAA,KAAAC,GAAA,KAAAC,EAAA,KAAAC,EAAA,KAAAC,GAAA,KAAAC,GAAA,KAAAC,GAAA,KAAAC,GAAA,KAAAC,EAAA,KAAAC,GAAA,KAAAC,EAAA,KAAAC,GAAA,KAAAC,GAAA,KAAAC,GAAA,KAAAC,GAAA,KAAAC,GAAA,KAAAC,OAAA,0CAAA,OAAA,KAAAC,OAAA,2CAAA,OAAA,KAAAC,OAAA,2CAaO,MAAMC,GAAU,CACrB,SAAUC,EACZ,EAQA,SAASA,GAAkBC,EAAS,CAClC,MAAMC,EAAeD,EAAQ,QAAQ,KAAK,OAAO,WAAW,eAAgBE,EAA4BC,CAAgB,EAExH,IAAIC,EACJ,OAAOH,EAGP,SAASC,EAA2BG,EAAM,CACxC,GAAIA,IAAS,KAAM,CACjBL,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAAL,EAAQ,MAAM,YAAY,EAC1BA,EAAQ,QAAQK,CAAI,EACpBL,EAAQ,KAAK,YAAY,EAClB9B,EAAa8B,EAASC,EAAc,YAAY,CAC3D,CAGE,SAASE,EAAiBE,EAAM,CAC9B,OAAAL,EAAQ,MAAM,WAAW,EAClBM,EAAUD,CAAI,CACzB,CAGE,SAASC,EAAUD,EAAM,CACvB,MAAME,EAAQP,EAAQ,MAAM,YAAa,CACvC,YAAa,OACb,SAAAI,CACN,CAAK,EACD,OAAIA,IACFA,EAAS,KAAOG,GAElBH,EAAWG,EACJC,EAAKH,CAAI,CACpB,CAGE,SAASG,EAAKH,EAAM,CAClB,GAAIA,IAAS,KAAM,CACjBL,EAAQ,KAAK,WAAW,EACxBA,EAAQ,KAAK,WAAW,EACxBA,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAIlC,EAAmBkC,CAAI,GACzBL,EAAQ,QAAQK,CAAI,EACpBL,EAAQ,KAAK,WAAW,EACjBM,IAITN,EAAQ,QAAQK,CAAI,EACbG,EACX,CACA,CCvDO,MAAMC,GAAW,CACtB,SAAUC,EACZ,EAGMC,GAAqB,CACzB,SAAUC,EACZ,EAQA,SAASF,GAAmBV,EAAS,CACnC,MAAMa,EAAO,KAEPC,EAAQ,CAAE,EAChB,IAAIC,EAAY,EAEZC,EAEAC,EAEAC,EACJ,OAAOC,EAGP,SAASA,EAAMd,EAAM,CAWnB,GAAIU,EAAYD,EAAM,OAAQ,CAC5B,MAAMM,EAAON,EAAMC,CAAS,EAC5B,OAAAF,EAAK,eAAiBO,EAAK,CAAC,EACrBpB,EAAQ,QAAQoB,EAAK,CAAC,EAAE,aAAcC,EAAkBC,CAAkB,EAAEjB,CAAI,CAC7F,CAGI,OAAOiB,EAAmBjB,CAAI,CAClC,CAGE,SAASgB,EAAiBhB,EAAM,CAM9B,GALAU,IAKIF,EAAK,eAAe,WAAY,CAClCA,EAAK,eAAe,WAAa,OAC7BG,GACFO,EAAW,EAKb,MAAMC,EAAmBX,EAAK,OAAO,OACrC,IAAIY,EAAkBD,EAElBE,EAGJ,KAAOD,KACL,GAAIZ,EAAK,OAAOY,CAAe,EAAE,CAAC,IAAM,QAAUZ,EAAK,OAAOY,CAAe,EAAE,CAAC,EAAE,OAAS,YAAa,CACtGC,EAAQb,EAAK,OAAOY,CAAe,EAAE,CAAC,EAAE,IACxC,KACV,CAEME,EAAeZ,CAAS,EAGxB,IAAIa,EAAQJ,EACZ,KAAOI,EAAQf,EAAK,OAAO,QACzBA,EAAK,OAAOe,CAAK,EAAE,CAAC,EAAE,IAAM,CAC1B,GAAGF,CACJ,EACDE,IAIF,OAAAxD,EAAOyC,EAAK,OAAQY,EAAkB,EAAG,EAAGZ,EAAK,OAAO,MAAMW,CAAgB,CAAC,EAG/EX,EAAK,OAAO,OAASe,EACdN,EAAmBjB,CAAI,CACpC,CACI,OAAOc,EAAMd,CAAI,CACrB,CAGE,SAASiB,EAAmBjB,EAAM,CAMhC,GAAIU,IAAcD,EAAM,OAAQ,CAI9B,GAAI,CAACE,EACH,OAAOa,EAAkBxB,CAAI,EAM/B,GAAIW,EAAU,kBAAoBA,EAAU,iBAAiB,SAC3D,OAAOc,EAAUzB,CAAI,EAQvBQ,EAAK,UAAY,GAAQG,EAAU,kBAAoB,CAACA,EAAU,8BACxE,CAGI,OAAAH,EAAK,eAAiB,CAAE,EACjBb,EAAQ,MAAMW,GAAoBoB,EAAsBC,CAAqB,EAAE3B,CAAI,CAC9F,CAGE,SAAS0B,EAAqB1B,EAAM,CAClC,OAAIW,GAAWO,EAAW,EAC1BI,EAAeZ,CAAS,EACjBc,EAAkBxB,CAAI,CACjC,CAGE,SAAS2B,EAAsB3B,EAAM,CACnC,OAAAQ,EAAK,OAAO,KAAKA,EAAK,IAAK,EAAC,IAAI,EAAIE,IAAcD,EAAM,OACxDI,EAAkBL,EAAK,IAAG,EAAG,OACtBiB,EAAUzB,CAAI,CACzB,CAGE,SAASwB,EAAkBxB,EAAM,CAE/B,OAAAQ,EAAK,eAAiB,CAAE,EACjBb,EAAQ,QAAQW,GAAoBsB,EAAmBH,CAAS,EAAEzB,CAAI,CACjF,CAGE,SAAS4B,EAAkB5B,EAAM,CAC/B,OAAAU,IACAD,EAAM,KAAK,CAACD,EAAK,iBAAkBA,EAAK,cAAc,CAAC,EAEhDgB,EAAkBxB,CAAI,CACjC,CAGE,SAASyB,EAAUzB,EAAM,CACvB,GAAIA,IAAS,KAAM,CACbW,GAAWO,EAAW,EAC1BI,EAAe,CAAC,EAChB3B,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAAW,EAAYA,GAAaH,EAAK,OAAO,KAAKA,EAAK,KAAK,EACpDb,EAAQ,MAAM,YAAa,CACzB,WAAYgB,EACZ,YAAa,OACb,SAAUC,CAChB,CAAK,EACMiB,EAAa7B,CAAI,CAC5B,CAGE,SAAS6B,EAAa7B,EAAM,CAC1B,GAAIA,IAAS,KAAM,CACjB8B,EAAanC,EAAQ,KAAK,WAAW,EAAG,EAAI,EAC5C2B,EAAe,CAAC,EAChB3B,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAIlC,EAAmBkC,CAAI,GACzBL,EAAQ,QAAQK,CAAI,EACpB8B,EAAanC,EAAQ,KAAK,WAAW,CAAC,EAEtCe,EAAY,EACZF,EAAK,UAAY,OACVM,IAETnB,EAAQ,QAAQK,CAAI,EACb6B,EACX,CAUE,SAASC,EAAa5B,EAAO6B,EAAW,CACtC,MAAMC,EAASxB,EAAK,YAAYN,CAAK,EAyCrC,GAxCI6B,GAAWC,EAAO,KAAK,IAAI,EAC/B9B,EAAM,SAAWU,EACbA,IAAYA,EAAW,KAAOV,GAClCU,EAAaV,EACbS,EAAU,WAAWT,EAAM,KAAK,EAChCS,EAAU,MAAMqB,CAAM,EAmClBxB,EAAK,OAAO,KAAKN,EAAM,MAAM,IAAI,EAAG,CACtC,IAAIqB,EAAQZ,EAAU,OAAO,OAC7B,KAAOY,KACL,GAEAZ,EAAU,OAAOY,CAAK,EAAE,CAAC,EAAE,MAAM,OAASV,IAE1C,CAACF,EAAU,OAAOY,CAAK,EAAE,CAAC,EAAE,KAE5BZ,EAAU,OAAOY,CAAK,EAAE,CAAC,EAAE,IAAI,OAASV,GAGtC,OAMJ,MAAMM,EAAmBX,EAAK,OAAO,OACrC,IAAIY,EAAkBD,EAElBc,EAEAZ,EAGJ,KAAOD,KACL,GAAIZ,EAAK,OAAOY,CAAe,EAAE,CAAC,IAAM,QAAUZ,EAAK,OAAOY,CAAe,EAAE,CAAC,EAAE,OAAS,YAAa,CACtG,GAAIa,EAAM,CACRZ,EAAQb,EAAK,OAAOY,CAAe,EAAE,CAAC,EAAE,IACxC,KACZ,CACUa,EAAO,EACjB,CAMM,IAJAX,EAAeZ,CAAS,EAGxBa,EAAQJ,EACDI,EAAQf,EAAK,OAAO,QACzBA,EAAK,OAAOe,CAAK,EAAE,CAAC,EAAE,IAAM,CAC1B,GAAGF,CACJ,EACDE,IAIFxD,EAAOyC,EAAK,OAAQY,EAAkB,EAAG,EAAGZ,EAAK,OAAO,MAAMW,CAAgB,CAAC,EAG/EX,EAAK,OAAO,OAASe,CAC3B,CACA,CAQE,SAASD,EAAeY,EAAM,CAC5B,IAAIX,EAAQd,EAAM,OAGlB,KAAOc,KAAUW,GAAM,CACrB,MAAMC,EAAQ1B,EAAMc,CAAK,EACzBf,EAAK,eAAiB2B,EAAM,CAAC,EAC7BA,EAAM,CAAC,EAAE,KAAK,KAAK3B,EAAMb,CAAO,CACtC,CACIc,EAAM,OAASyB,CACnB,CACE,SAAShB,GAAY,CACnBP,EAAU,MAAM,CAAC,IAAI,CAAC,EACtBC,EAAa,OACbD,EAAY,OACZH,EAAK,eAAe,WAAa,MACrC,CACA,CAQA,SAASD,GAAkBZ,EAASyC,EAAIC,EAAK,CAG3C,OAAOxE,EAAa8B,EAASA,EAAQ,QAAQ,KAAK,OAAO,WAAW,SAAUyC,EAAIC,CAAG,EAAG,aAAc,KAAK,OAAO,WAAW,QAAQ,KAAK,SAAS,cAAc,EAAI,OAAY,CAAC,CACpL,CC5VO,MAAMC,GAAO,CAClB,SAAUC,EACZ,EAQA,SAASA,GAAe5C,EAAS,CAC/B,MAAMa,EAAO,KACPgC,EAAU7C,EAAQ,QAExB1B,GAAWwE,EAEX9C,EAAQ,QAAQ,KAAK,OAAO,WAAW,YAAa+C,EAAgB7E,EAAa8B,EAASA,EAAQ,QAAQ,KAAK,OAAO,WAAW,KAAM+C,EAAgB/C,EAAQ,QAAQF,GAASiD,CAAc,CAAC,EAAG,YAAY,CAAC,CAAC,EAChN,OAAOF,EAGP,SAASC,EAAczC,EAAM,CAC3B,GAAIA,IAAS,KAAM,CACjBL,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAAL,EAAQ,MAAM,iBAAiB,EAC/BA,EAAQ,QAAQK,CAAI,EACpBL,EAAQ,KAAK,iBAAiB,EAC9Ba,EAAK,iBAAmB,OACjBgC,CACX,CAGE,SAASE,EAAe1C,EAAM,CAC5B,GAAIA,IAAS,KAAM,CACjBL,EAAQ,QAAQK,CAAI,EACpB,MACN,CACI,OAAAL,EAAQ,MAAM,YAAY,EAC1BA,EAAQ,QAAQK,CAAI,EACpBL,EAAQ,KAAK,YAAY,EACzBa,EAAK,iBAAmB,OACjBgC,CACX,CACA,CC9CO,MAAMG,GAAW,CACtB,WAAYC,GAAc,CAC5B,EACaC,GAASC,GAAkB,QAAQ,EACnCC,GAAOD,GAAkB,MAAM,EAQ5C,SAASA,GAAkBE,EAAO,CAChC,MAAO,CACL,WAAYJ,GAAeI,IAAU,OAASC,GAAyB,MAAS,EAChF,SAAUC,CACX,EAOD,SAASA,EAAevD,EAAS,CAC/B,MAAMa,EAAO,KACP2C,EAAa,KAAK,OAAO,WAAWH,CAAK,EACzCD,EAAOpD,EAAQ,QAAQwD,EAAYrC,EAAOsC,CAAO,EACvD,OAAOtC,EAGP,SAASA,EAAMd,EAAM,CACnB,OAAOqD,EAAQrD,CAAI,EAAI+C,EAAK/C,CAAI,EAAIoD,EAAQpD,CAAI,CACtD,CAGI,SAASoD,EAAQpD,EAAM,CACrB,GAAIA,IAAS,KAAM,CACjBL,EAAQ,QAAQK,CAAI,EACpB,MACR,CACM,OAAAL,EAAQ,MAAM,MAAM,EACpBA,EAAQ,QAAQK,CAAI,EACbG,CACb,CAGI,SAASA,EAAKH,EAAM,CAClB,OAAIqD,EAAQrD,CAAI,GACdL,EAAQ,KAAK,MAAM,EACZoD,EAAK/C,CAAI,IAIlBL,EAAQ,QAAQK,CAAI,EACbG,EACb,CAQI,SAASkD,EAAQrD,EAAM,CACrB,GAAIA,IAAS,KACX,MAAO,GAET,MAAM7B,EAAOgF,EAAWnD,CAAI,EAC5B,IAAIuB,EAAQ,GACZ,GAAIpD,EAGF,KAAO,EAAEoD,EAAQpD,EAAK,QAAQ,CAC5B,MAAM4C,EAAO5C,EAAKoD,CAAK,EACvB,GAAI,CAACR,EAAK,UAAYA,EAAK,SAAS,KAAKP,EAAMA,EAAK,QAAQ,EAC1D,MAAO,EAEnB,CAEM,MAAO,EACb,CACA,CACA,CAQA,SAASoC,GAAeU,EAAe,CACrC,OAAOC,EAGP,SAASA,EAAeC,EAAQC,EAAS,CACvC,IAAIlC,EAAQ,GAERmC,EAIJ,KAAO,EAAEnC,GAASiC,EAAO,QACnBE,IAAU,OACRF,EAAOjC,CAAK,GAAKiC,EAAOjC,CAAK,EAAE,CAAC,EAAE,OAAS,SAC7CmC,EAAQnC,EACRA,MAEO,CAACiC,EAAOjC,CAAK,GAAKiC,EAAOjC,CAAK,EAAE,CAAC,EAAE,OAAS,UAEjDA,IAAUmC,EAAQ,IACpBF,EAAOE,CAAK,EAAE,CAAC,EAAE,IAAMF,EAAOjC,EAAQ,CAAC,EAAE,CAAC,EAAE,IAC5CiC,EAAO,OAAOE,EAAQ,EAAGnC,EAAQmC,EAAQ,CAAC,EAC1CnC,EAAQmC,EAAQ,GAElBA,EAAQ,QAGZ,OAAOJ,EAAgBA,EAAcE,EAAQC,CAAO,EAAID,CAC5D,CACA,CAaA,SAASP,GAAuBO,EAAQC,EAAS,CAC/C,IAAIE,EAAa,EAEjB,KAAO,EAAEA,GAAcH,EAAO,QAC5B,IAAKG,IAAeH,EAAO,QAAUA,EAAOG,CAAU,EAAE,CAAC,EAAE,OAAS,eAAiBH,EAAOG,EAAa,CAAC,EAAE,CAAC,EAAE,OAAS,OAAQ,CAC9H,MAAMxD,EAAOqD,EAAOG,EAAa,CAAC,EAAE,CAAC,EAC/BC,EAASH,EAAQ,YAAYtD,CAAI,EACvC,IAAIoB,EAAQqC,EAAO,OACfC,EAAc,GACd3B,EAAO,EAEP4B,EACJ,KAAOvC,KAAS,CACd,MAAMwC,EAAQH,EAAOrC,CAAK,EAC1B,GAAI,OAAOwC,GAAU,SAAU,CAE7B,IADAF,EAAcE,EAAM,OACbA,EAAM,WAAWF,EAAc,CAAC,IAAM,IAC3C3B,IACA2B,IAEF,GAAIA,EAAa,MACjBA,EAAc,EACxB,SAEiBE,IAAU,GACjBD,EAAO,GACP5B,YACS6B,IAAU,GAEd,CAELxC,IACA,KACV,CACA,CACM,GAAIW,EAAM,CACR,MAAMhC,EAAQ,CACZ,KAAMyD,IAAeH,EAAO,QAAUM,GAAQ5B,EAAO,EAAI,aAAe,oBACxE,MAAO,CACL,aAAcX,EAAQsC,EAAc1D,EAAK,MAAM,aAAe0D,EAC9D,OAAQ1D,EAAK,MAAM,OAASoB,EAC5B,KAAMpB,EAAK,IAAI,KACf,OAAQA,EAAK,IAAI,OAAS+B,EAC1B,OAAQ/B,EAAK,IAAI,OAAS+B,CAC3B,EACD,IAAK,CACH,GAAG/B,EAAK,GACpB,CACS,EACDA,EAAK,IAAM,CACT,GAAGD,EAAM,KACV,EACGC,EAAK,MAAM,SAAWA,EAAK,IAAI,OACjC,OAAO,OAAOA,EAAMD,CAAK,GAEzBsD,EAAO,OAAOG,EAAY,EAAG,CAAC,QAASzD,EAAOuD,CAAO,EAAG,CAAC,OAAQvD,EAAOuD,CAAO,CAAC,EAChFE,GAAc,EAExB,CACMA,GACN,CAEE,OAAOH,CACT,CCtMO,MAAMpD,GAAW,CACrB,GAAKjC,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKA,EACL,GAAKC,EACR,EAGa4F,GAAiB,CAC3B,GAAK3F,EACR,EAGa4F,GAAc,CACzB,CAAC,EAAE,EAAG3F,EACN,CAAC,EAAE,EAAGA,EACL,GAAKA,CACR,EAGagE,GAAO,CACjB,GAAK/D,GACL,GAAKC,EACL,GAAK,CAACC,EAAiBD,CAAa,EACpC,GAAKE,GACL,GAAKD,EACL,GAAKD,EACL,GAAKG,GACL,IAAMA,EACT,EAGakE,GAAS,CACnB,GAAKjE,GACL,GAAKC,EACR,EAGakE,GAAO,CAClB,CAAC,EAAE,EAAGjE,EACN,CAAC,EAAE,EAAGA,EACN,CAAC,EAAE,EAAGA,EACL,GAAKC,GACL,GAAKH,GACL,GAAKI,EACL,GAAK,CAACC,GAAUC,EAAQ,EACxB,GAAKC,GACL,GAAK,CAACC,GAAiBP,EAAe,EACtC,GAAKQ,GACL,GAAKL,EACL,GAAKM,EACR,EAGa4E,GAAa,CACxB,KAAM,CAAClF,EAAWmF,EAAW,CAC/B,EAGaC,GAAmB,CAC9B,KAAM,CAAC,GAAI,EAAE,CACf,EAGaC,GAAU,CACrB,KAAM,CAAA,CACR,ECpFAC,GAAA,OAAA,OAAA,OAAA,eAAA,CAAA,UAAA,KAAA,iBAAAF,GAAA,eAAAJ,GAAA,QAAAK,GAAA,SAAAjE,GAAA,KAAAkC,GAAA,YAAA2B,GAAA,WAAAC,GAAA,OAAArB,GAAA,KAAAE,EAAA,EAAA,OAAA,YAAA,CAAA,MAAA,QAAA,CAAA,CAAA,EA4DO,SAASwB,GAAgBC,EAAQC,EAAYC,EAAM,CAExD,IAAIrD,EAAQ,CACV,aAAc,GACd,OAAQ,EACR,KAAMqD,GAAQA,EAAK,MAAQ,EAC3B,OAAQA,GAAQA,EAAK,QAAU,EAC/B,OAAQA,GAAQA,EAAK,QAAU,CAChC,EAED,MAAMC,EAAc,CAAE,EAEhBC,EAAuB,CAAE,EAE/B,IAAIhB,EAAS,CAAE,EAEXnD,EAAQ,CAAE,EASd,MAAMd,EAAU,CACd,QAASkF,EAAiBC,CAAqB,EAC/C,MAAOD,EAAiBE,CAAiB,EACzC,QAAAC,EACA,MAAAtB,EACA,KAAAuB,EACA,UAAWJ,EAAiBE,EAAmB,CAC7C,UAAW,EACZ,CAAA,CACF,EAOKtB,EAAU,CACd,KAAM,KACN,eAAgB,CAAE,EAClB,WAAAyB,EACA,OAAQ,CAAE,EACV,IAAAC,EACA,OAAAX,EACA,SAAU,KACV,eAAAY,EACA,YAAAC,EACA,MAAAC,CACD,EAOD,IAAIC,EAAQd,EAAW,SAAS,KAAKhB,EAAS9D,CAAO,EAQrD,OAAI8E,EAAW,YACbG,EAAqB,KAAKH,CAAU,EAE/BhB,EAGP,SAAS6B,EAAME,EAAO,CAKpB,OAJA5B,EAAS5F,GAAK4F,EAAQ4B,CAAK,EAC3BC,EAAM,EAGF7B,EAAOA,EAAO,OAAS,CAAC,IAAM,KACzB,CAAE,GAEX8B,EAAUjB,EAAY,CAAC,EAGvBhB,EAAQ,OAASlE,GAAWqF,EAAsBnB,EAAQ,OAAQA,CAAO,EAClEA,EAAQ,OACnB,CAOE,SAAS2B,EAAelF,EAAOyF,EAAY,CACzC,OAAOC,GAAgBP,EAAYnF,CAAK,EAAGyF,CAAU,CACzD,CAGE,SAASN,EAAYnF,EAAO,CAC1B,OAAO2F,GAAYjC,EAAQ1D,CAAK,CACpC,CAGE,SAASiF,GAAM,CAEb,KAAM,CACJ,aAAAW,EACA,OAAAC,EACA,KAAAC,EACA,OAAAC,EACA,OAAAC,CACN,EAAQ7E,EACJ,MAAO,CACL,aAAAyE,EACA,OAAAC,EACA,KAAAC,EACA,OAAAC,EACA,OAAAC,CACD,CACL,CAGE,SAAShB,EAAWiB,EAAO,CACzBxB,EAAYwB,EAAM,IAAI,EAAIA,EAAM,OAChCC,EAAyB,CAC7B,CAiBE,SAASX,GAAO,CAEd,IAAIY,EACJ,KAAOhF,EAAM,OAASuC,EAAO,QAAQ,CACnC,MAAMG,EAAQH,EAAOvC,EAAM,MAAM,EAGjC,GAAI,OAAO0C,GAAU,SAKnB,IAJAsC,EAAahF,EAAM,OACfA,EAAM,aAAe,IACvBA,EAAM,aAAe,GAEhBA,EAAM,SAAWgF,GAAchF,EAAM,aAAe0C,EAAM,QAC/DuC,EAAGvC,EAAM,WAAW1C,EAAM,YAAY,CAAC,OAGzCiF,EAAGvC,CAAK,CAEhB,CACA,CAUE,SAASuC,EAAGtG,EAAM,CAGhBuF,EAAQA,EAAMvF,CAAI,CACtB,CAGE,SAASgF,EAAQhF,EAAM,CACjBlC,EAAmBkC,CAAI,GACzBqB,EAAM,OACNA,EAAM,OAAS,EACfA,EAAM,QAAUrB,IAAS,GAAK,EAAI,EAClCoG,EAAyB,GAChBpG,IAAS,KAClBqB,EAAM,SACNA,EAAM,UAIJA,EAAM,aAAe,EACvBA,EAAM,UAENA,EAAM,eAGFA,EAAM,eAIVuC,EAAOvC,EAAM,MAAM,EAAE,SACnBA,EAAM,aAAe,GACrBA,EAAM,WAKVoC,EAAQ,SAAWzD,CAIvB,CAGE,SAAS0D,EAAM6C,EAAMC,EAAQ,CAG3B,MAAMtG,EAAQsG,GAAU,CAAE,EAC1B,OAAAtG,EAAM,KAAOqG,EACbrG,EAAM,MAAQiF,EAAK,EACnB1B,EAAQ,OAAO,KAAK,CAAC,QAASvD,EAAOuD,CAAO,CAAC,EAC7ChD,EAAM,KAAKP,CAAK,EACTA,CACX,CAGE,SAAS+E,EAAKsB,EAAM,CAClB,MAAMrG,EAAQO,EAAM,IAAK,EACzB,OAAAP,EAAM,IAAMiF,EAAK,EACjB1B,EAAQ,OAAO,KAAK,CAAC,OAAQvD,EAAOuD,CAAO,CAAC,EACrCvD,CACX,CAOE,SAAS4E,EAAsB2B,EAAWC,EAAM,CAC9ChB,EAAUe,EAAWC,EAAK,IAAI,CAClC,CAOE,SAAS3B,EAAkB4B,EAAGD,EAAM,CAClCA,EAAK,QAAS,CAClB,CAUE,SAAS7B,EAAiB+B,EAAUJ,EAAQ,CAC1C,OAAOK,EAeP,SAASA,EAAK1D,EAAY2D,EAAaC,EAAY,CAEjD,IAAIC,EAEAC,EAEAC,EAEAR,EACJ,OAAO,MAAM,QAAQvD,CAAU,EAC/BgE,EAAuBhE,CAAU,EAAI,aAAcA,EAEnDgE,EAAuB,CAA0BhE,CAAU,CAAE,EAAIiE,GAAsBjE,CAAU,EAUjG,SAASiE,GAAsBC,EAAK,CAClC,OAAOvG,EAGP,SAASA,EAAMd,EAAM,CACnB,MAAMsH,EAAOtH,IAAS,MAAQqH,EAAIrH,CAAI,EAChCuH,EAAMvH,IAAS,MAAQqH,EAAI,KAC3BlJ,GAAO,CAGb,GAAI,MAAM,QAAQmJ,CAAI,EAAIA,EAAOA,EAAO,CAACA,CAAI,EAAI,CAAE,EAAG,GAAI,MAAM,QAAQC,CAAG,EAAIA,EAAMA,EAAM,CAACA,CAAG,EAAI,CAAA,CAAG,EACtG,OAAOJ,EAAuBhJ,EAAI,EAAE6B,CAAI,CAClD,CACA,CAUM,SAASmH,EAAuBhJ,EAAM,CAGpC,OAFA6I,EAAmB7I,EACnB8I,EAAiB,EACb9I,EAAK,SAAW,EACX4I,EAEFS,EAAgBrJ,EAAK8I,CAAc,CAAC,CACnD,CAUM,SAASO,EAAgBf,EAAW,CAClC,OAAO3F,EAGP,SAASA,EAAMd,EAAM,CAanB,OARA0G,EAAOe,EAAO,EACdP,EAAmBT,EACdA,EAAU,UACbhD,EAAQ,iBAAmBgD,GAKzBA,EAAU,MAAQhD,EAAQ,OAAO,WAAW,QAAQ,KAAK,SAASgD,EAAU,IAAI,EAC3EpE,EAAQ,EAEVoE,EAAU,SAAS,KAI1BD,EAAS,OAAO,OAAO,OAAO,OAAO/C,CAAO,EAAG+C,CAAM,EAAI/C,EAAS9D,EAASyC,GAAIC,CAAG,EAAErC,CAAI,CAClG,CACA,CAGM,SAASoC,GAAGpC,EAAM,CAEhB,OAAA4G,EAASM,EAAkBR,CAAI,EACxBI,CACf,CAGM,SAASzE,EAAIrC,EAAM,CAGjB,OADA0G,EAAK,QAAS,EACV,EAAEO,EAAiBD,EAAiB,OAC/BQ,EAAgBR,EAAiBC,CAAc,CAAC,EAElDF,CACf,CACA,CACA,CAUE,SAASrB,EAAUe,EAAW/B,EAAM,CAC9B+B,EAAU,YAAc,CAAC7B,EAAqB,SAAS6B,CAAS,GAClE7B,EAAqB,KAAK6B,CAAS,EAEjCA,EAAU,SACZ1I,EAAO0F,EAAQ,OAAQiB,EAAMjB,EAAQ,OAAO,OAASiB,EAAM+B,EAAU,QAAQhD,EAAQ,OAAO,MAAMiB,CAAI,EAAGjB,CAAO,CAAC,EAE/GgD,EAAU,YACZhD,EAAQ,OAASgD,EAAU,UAAUhD,EAAQ,OAAQA,CAAO,EAElE,CAQE,SAASgE,GAAQ,CACf,MAAMC,EAAavC,EAAK,EAClBwC,EAAgBlE,EAAQ,SACxBmE,EAAwBnE,EAAQ,iBAChCoE,EAAmBpE,EAAQ,OAAO,OAClCqE,EAAa,MAAM,KAAKrH,CAAK,EACnC,MAAO,CACL,KAAMoH,EACN,QAAAE,CACD,EAQD,SAASA,GAAU,CACjB1G,EAAQqG,EACRjE,EAAQ,SAAWkE,EACnBlE,EAAQ,iBAAmBmE,EAC3BnE,EAAQ,OAAO,OAASoE,EACxBpH,EAAQqH,EACR1B,EAAyB,CAC/B,CACA,CASE,SAASA,GAA0B,CAC7B/E,EAAM,QAAQsD,GAAetD,EAAM,OAAS,IAC9CA,EAAM,OAASsD,EAAYtD,EAAM,IAAI,EACrCA,EAAM,QAAUsD,EAAYtD,EAAM,IAAI,EAAI,EAEhD,CACA,CAYA,SAASwE,GAAYjC,EAAQ1D,EAAO,CAClC,MAAM8H,EAAa9H,EAAM,MAAM,OACzB+H,EAAmB/H,EAAM,MAAM,aAC/BgI,EAAWhI,EAAM,IAAI,OACrBiI,EAAiBjI,EAAM,IAAI,aAEjC,IAAIkI,EACJ,GAAIJ,IAAeE,EAEjBE,EAAO,CAACxE,EAAOoE,CAAU,EAAE,MAAMC,EAAkBE,CAAc,CAAC,MAC7D,CAEL,GADAC,EAAOxE,EAAO,MAAMoE,EAAYE,CAAQ,EACpCD,EAAmB,GAAI,CACzB,MAAMI,EAAOD,EAAK,CAAC,EACf,OAAOC,GAAS,SAClBD,EAAK,CAAC,EAAIC,EAAK,MAAMJ,CAAgB,EAErCG,EAAK,MAAO,CAEpB,CACQD,EAAiB,GAEnBC,EAAK,KAAKxE,EAAOsE,CAAQ,EAAE,MAAM,EAAGC,CAAc,CAAC,CAEzD,CACE,OAAOC,CACT,CAYA,SAASxC,GAAgBhC,EAAQ+B,EAAY,CAC3C,IAAIpE,EAAQ,GAEZ,MAAM+G,EAAS,CAAE,EAEjB,IAAIC,EACJ,KAAO,EAAEhH,EAAQqC,EAAO,QAAQ,CAC9B,MAAMG,EAAQH,EAAOrC,CAAK,EAE1B,IAAI4E,EACJ,GAAI,OAAOpC,GAAU,SACnBoC,EAAQpC,MACH,QAAQA,EAAK,CAClB,IAAK,GACH,CACEoC,EAAQ,KACR,KACV,CACM,IAAK,GACH,CACEA,EAAQ;AAAA,EACR,KACV,CACM,IAAK,GACH,CACEA,EAAQ;AAAA,EACR,KACV,CACM,IAAK,GACH,CACEA,EAAQR,EAAa,IAAM,IAC3B,KACV,CACM,IAAK,GACH,CACE,GAAI,CAACA,GAAc4C,EAAO,SAC1BpC,EAAQ,IACR,KACV,CACM,QAGIA,EAAQ,OAAO,aAAapC,CAAK,CAE3C,CACIwE,EAAQxE,IAAU,GAClBuE,EAAO,KAAKnC,CAAK,CACrB,CACE,OAAOmC,EAAO,KAAK,EAAE,CACvB,CCzkBO,SAASE,GAAMC,EAAS,CAM7B,MAAMjE,EAAS,CACb,WAJF5G,GAAkB,CAAC0G,GAAmB,IAFrBmE,GAAW,CAAE,GAEqB,YAAc,CAAE,CAAC,CAAC,EAKnE,QAASC,EAAOjJ,EAAO,EACvB,QAAS,CAAE,EACX,SAAUiJ,EAAOtI,EAAQ,EACzB,KAAMsI,EAAOpG,EAAI,EACjB,KAAM,CAAE,EACR,OAAQoG,EAAO7F,EAAM,EACrB,KAAM6F,EAAO3F,EAAI,CAClB,EACD,OAAOyB,EAQP,SAASkE,EAAOlG,EAAS,CACvB,OAAOmG,EAEP,SAASA,EAAQjE,EAAM,CACrB,OAAOH,GAAgBC,EAAQhC,EAASkC,CAAI,CAClD,CACA,CACA,CC3CO,SAASkE,GAAYpF,EAAQ,CAClC,KAAO,CAAChE,GAAYgE,CAAM,GAAG,CAG7B,OAAOA,CACT,CCAA,MAAMqF,GAAS,cAMR,SAASC,IAAa,CAC3B,IAAI7C,EAAS,EACT8C,EAAS,GAETjI,EAAQ,GAERkI,EACJ,OAAOC,EAIP,SAASA,EAAa9C,EAAO+C,EAAUC,EAAK,CAE1C,MAAMvF,EAAS,CAAE,EAEjB,IAAIwF,EAEAC,EAEAC,EAEAC,EAEAvJ,EAWJ,IAVAmG,EAAQ4C,GAAU,OAAO5C,GAAU,SAAWA,EAAM,SAAQ,EAAK,IAAI,YAAY+C,GAAY,MAAS,EAAE,OAAO/C,CAAK,GACpHmD,EAAgB,EAChBP,EAAS,GACLjI,IAEEqF,EAAM,WAAW,CAAC,IAAM,OAC1BmD,IAEFxI,EAAQ,QAEHwI,EAAgBnD,EAAM,QAAQ,CAKnC,GAJA0C,GAAO,UAAYS,EACnBF,EAAQP,GAAO,KAAK1C,CAAK,EACzBoD,EAAcH,GAASA,EAAM,QAAU,OAAYA,EAAM,MAAQjD,EAAM,OACvEnG,EAAOmG,EAAM,WAAWoD,CAAW,EAC/B,CAACH,EAAO,CACVL,EAAS5C,EAAM,MAAMmD,CAAa,EAClC,KACR,CACM,GAAItJ,IAAS,IAAMsJ,IAAkBC,GAAeP,EAClDpF,EAAO,KAAK,EAAE,EACdoF,EAAmB,WAUnB,QARIA,IACFpF,EAAO,KAAK,EAAE,EACdoF,EAAmB,QAEjBM,EAAgBC,IAClB3F,EAAO,KAAKuC,EAAM,MAAMmD,EAAeC,CAAW,CAAC,EACnDtD,GAAUsD,EAAcD,GAElBtJ,EAAI,CACV,IAAK,GACH,CACE4D,EAAO,KAAK,KAAK,EACjBqC,IACA,KACd,CACU,IAAK,GACH,CAGE,IAFAoD,EAAO,KAAK,KAAKpD,EAAS,CAAC,EAAI,EAC/BrC,EAAO,KAAK,EAAE,EACPqC,IAAWoD,GAAMzF,EAAO,KAAK,EAAE,EACtC,KACd,CACU,IAAK,IACH,CACEA,EAAO,KAAK,EAAE,EACdqC,EAAS,EACT,KACd,CACU,QAEI+C,EAAmB,GACnB/C,EAAS,CAEvB,CAEMqD,EAAgBC,EAAc,CACpC,CACI,OAAIJ,IACEH,GAAkBpF,EAAO,KAAK,EAAE,EAChCmF,GAAQnF,EAAO,KAAKmF,CAAM,EAC9BnF,EAAO,KAAK,IAAI,GAEXA,CACX,CACA","x_google_ignoreList":[0,1,2,3,4,5,6,7,8]}